---
name: tech-longlist-verifier
description: tech-longlist-creatorで作成された技術ロングリストExcelファイルの内容が、*情報ソースの原文に基づいた事実*であるかを検証する。各項目について原文との照合を行い、ハルシネーション（推測・拡大解釈・一般論）を検出し、事実性スコアと詳細な検証レポートを生成する。研究開発部門の技術調査品質保証、情報の信頼性確認、レポート精度向上に使用する。
---

# Tech Longlist Verifier

tech-longlist-creatorで作成された技術ロングリストの事実性を検証し、*情報ソースの原文に基づいているか*を確認する品質保証スキル。

## Overview

このスキルは、技術ロングリストの各項目について、情報ソースURLの原文内容と照合し、以下を検証する:
- 記載内容が原文に存在するか
- 定量値の記載内容が原文に存在するか
- 推測や拡大解釈が含まれていないか
- 一般論や確認できない情報が混入していないか
- 文章表現が適切か（である調、体言止め禁止など）

## Workflow

### Step 1: 入力ファイルの読み込み

以下のファイルを読み込む:
1. **技術ロングリストExcel**: 検証対象のロングリスト
2. 各行から以下の情報を抽出:
   - ID
   - タイトル
   - 概要1-4
   - 注目ポイント1-3
   - 技術開発の進展度
   - 主要情報ソースURL
   - 情報ソースURL 1-20
   - その他全項目

### Step 2: 情報ソースの取得

各行について:
1. **主要情報ソースURL**および**情報ソースURL 1-20**から原文を取得
2. WebFetchツールを使用して実際のコンテンツを取得
3. 取得失敗の場合はその旨を記録

### Step 3: 事実性検証

各項目について以下を検証:

#### 3.1 タイトルの検証
- 製品名/技術名が原文に存在するか
- 技術的特徴の記述が原文に基づいているか
- マーケティング的誇張表現が含まれていないか

#### 3.2 概要1の検証
- 組織名が原文と一致するか
- 開発/研究/販売の事実が原文に記載されているか
- 国名情報が正確か

#### 3.3 概要2の検証
- 材料、デバイス、サービスの原理・機能・構造の記述が原文に存在するか
- 技術的詳細が原文と一致するか
- 推測や拡大解釈が含まれていないか

#### 3.4 概要3の検証
- 成果や特性のデータが原文に明記されているか
- 数値データが正確か
- 検証機関名などが正確か

#### 3.5 概要4の検証
- 用途情報が原文に記載されているか
- ターゲット情報が正確か

#### 3.6 注目ポイント1-3の検証
- 課題、背景が原文に記載されているか
- 新規性、進歩性、優位性の記述が原文に基づいているか
- 特許番号、論文情報が正確か

#### 3.7 技術情報詳細の検証
- 技術開発の進展度が原文の記述と整合するか
- 発表年/出願年が正確か

#### 3.8 組織情報の検証
- 組織名（英語正式名称）が正確か
- 組織タイプ、国名、設立年、URLが正確か

### Step 4: ハルシネーション検出

以下のパターンを検出:

#### 禁止表現の検出
- 世界初
- 革新的
- 画期的
- 完全に
- 新時代の

#### 推測表現の検出
- 「～と考えられる」
- 「～の可能性がある」
- 「～と推測される」

#### 一般論の混入検出
- 原文に記載のない業界動向
- 原文に記載のない一般的な課題
- 確認できない比較情報

#### 拡大解釈の検出
- 原文の表現を超えた記述
- 原文にない因果関係の主張
- 数値の誇張や曲解

### Step 5: 文章表現の検証

tech-longlist-creatorの文章作成ガイドラインに従っているかを確認:

#### 文体チェック
- [ ] である調で統一されているか
- [ ] 体言止めを使用していないか

#### 表記チェック
- [ ] 全角括弧（）を使用しているか
- [ ] 数字と単位の間に半角スペースがあるか
- [ ] 商標記号を除去しているか

#### 用語チェック
- [ ] 専門用語に説明を付けているか
- [ ] 略語を初出時に定義しているか
- [ ] 用語が統一されているか
- [ ] 組織名を英語で記載しているか

#### 主語チェック
- [ ] 概要1で組織名を主語としているか
- [ ] 概要2-3で「同技術」「同サービス」「同研究」などで統一しているか

#### 文字数チェック
- [ ] 各項目の文字数制限を守っているか

### Step 6: 事実性スコアリング

各項目について以下の基準でスコアリング:

#### スコア定義
- **100点**: 完全に原文に基づいており、推測や拡大解釈なし
- **80-99点**: ほぼ原文に基づいているが、軽微な表現の調整あり
- **60-79点**: 原文に基づいているが、一部推測や補足情報あり
- **40-59点**: 原文の情報と推測が混在
- **20-39点**: 推測や拡大解釈が多く含まれる
- **0-19点**: 原文に基づいていない、またはハルシネーション

#### 評価基準
各項目について以下を評価:
1. **原文存在性** (40点): 記載内容が原文に明記されているか
2. **正確性** (30点): 数値、固有名詞、事実関係が正確か
3. **客観性** (20点): 推測や拡大解釈がないか
4. **表現適切性** (10点): 文体、用語、表記が適切か

### Step 7: 検証レポート生成

以下の形式で検証レポートを生成:

#### レポート構成

```markdown
# 技術ロングリスト検証レポート

## サマリー
- 検証日時: YYYY-MM-DD HH:MM:SS
- 総行数: N行
- 平均事実性スコア: XX.X点
- 問題検出数: N件
- 重大問題数: N件

## 総合評価
[A/B/C/D評価と総評]

## 詳細検証結果

### ID: [調査対象ID]
#### 基本情報
- タイトル: [タイトル]
- 組織名: [組織名]
- 主要情報ソースURL: [URL]

#### 事実性スコア: XX点 / 100点

#### 検証結果

##### タイトル [スコア: XX/100]
- ✅ 原文確認: [確認結果]
- ⚠️ 問題点: [問題があれば記載]
- 📝 原文引用: "[原文の該当箇所]"
- 💡 推奨修正: [修正が必要な場合]

##### 概要1 [スコア: XX/100]
- ✅ 原文確認: [確認結果]
- ⚠️ 問題点: [問題があれば記載]
- 📝 原文引用: "[原文の該当箇所]"
- 💡 推奨修正: [修正が必要な場合]

##### 概要2 [スコア: XX/100]
[同様の形式で各項目を検証]

##### 概要3 [スコア: XX/100]
[同様の形式]

##### 概要4 [スコア: XX/100]
[同様の形式]

##### 注目ポイント1 [スコア: XX/100]
[同様の形式]

##### 注目ポイント2 [スコア: XX/100]
[同様の形式]

##### 注目ポイント3 [スコア: XX/100]
[同様の形式]

##### 技術情報詳細 [スコア: XX/100]
[同様の形式]

##### 組織情報 [スコア: XX/100]
[同様の形式]

#### ハルシネーション検出
- 禁止表現: [検出された表現のリスト]
- 推測表現: [検出された表現のリスト]
- 一般論混入: [検出された箇所のリスト]
- 拡大解釈: [検出された箇所のリスト]

#### 文章表現の問題
- 文体の問題: [である調、体言止めなどの問題]
- 表記の問題: [括弧、スペース、商標記号などの問題]
- 用語の問題: [専門用語、略語、組織名などの問題]
- 主語の問題: [主語の統一に関する問題]
- 文字数の問題: [文字数制限違反]

#### 総合コメント
[この行の全体的な評価と改善提案]

---

[次の行についても同様に検証]

```

### Step 8: 改善提案の生成と検証情報統合

検出された問題について、以下を提案:

#### 1. 事実性の改善
- 原文に基づいた正確な記述への修正案
- 推測部分の削除または原文に基づく記述への置き換え
- 拡大解釈の修正

#### 2. 文章表現の改善
- 文体の統一（である調）
- 体言止めの修正
- 表記の修正（括弧、スペース、商標記号）
- 用語の統一と定義の追加

#### 3. 情報の補完
- 原文に存在するが記載されていない重要情報
- より正確な表現への修正提案

#### 4. 修正版Excelへの検証情報統合

tech-longlist-creatorの修正フェーズで使用するために、検証情報を構造化データとして提供する。修正版技術ロングリストExcelファイルの最後尾に以下の検証情報列を追加することを想定:

##### 追加する検証情報列（9列）

1. **検証スコア**
   - 内容: 各行の総合事実性スコア
   - 形式: 数値 (0-100点)
   - 例: 85

2. **評価ランク**
   - 内容: 総合評価のランク分類
   - 形式: A/B/C/D
   - 基準:
     * A: 90-100点（軽微な修正のみで使用可能）
     * B: 70-89点（部分的な修正で使用可能）
     * C: 50-69点（相当の修正が必要）
     * D: 0-49点（大幅な修正または再作成が必要）

3. **検出問題数**
   - 内容: この行で検出された問題の総数
   - 形式: 数値
   - 例: 5

4. **主な問題**
   - 内容: 最も重要な問題の簡潔な説明（最大3件まで）
   - 形式: セミコロン区切りテキスト
   - 例: 推測表現あり;数値の誤り;組織名表記ミス

5. **修正状況**
   - 内容: 修正フェーズでの対応状況
   - 形式: 修正済み/部分修正/未修正/修正不要
   - 判定基準:
     * 修正済み: 検出された全問題が修正された
     * 部分修正: 一部の問題のみ修正された
     * 未修正: 問題が残っている
     * 修正不要: 問題が検出されなかった

6. **検証レポート参照**
   - 内容: 詳細な検証レポートMarkdownファイル名
   - 形式: ファイル名
   - 例: verification_report_20250106_143045.md

7. **修正項目一覧**
   - 内容: 修正が行われた項目名と修正タイプのリスト
   - 形式: `[項目名]×[修正タイプ] | [項目名]×[修正タイプ] | ...`
   - 修正タイプ:
     * 誤字: 誤字脱字の修正
     * ハルシネ削除: ハルシネーション表現の削除
     * 数値訂正: 数値データの訂正
     * 表現改善: 文体・表記の改善
     * 情報追加: 不足情報の追加
     * 情報削除: 不適切情報の削除
   - 例: `タイトル×誤字 | 概要1×ハルシネ削除 | 概要3×数値訂正 | 注目2×表現改善`
   - 修正不要の場合: `なし`

8. **主要修正Before/After**
   - 内容: 最も重要な修正箇所のBefore/After比較（最大3件）
   - 形式: `[項目名] Before: [元テキスト50文字]... → After: [修正テキスト50文字]...`
     複数ある場合は改行で区切る
   - 例:
     ```
     [タイトル] Before: AI開発プラットフォームの革新的な新機能を提供... → After: AI開発プラットフォームの新機能を提供...
     [概要1] Before: 当社の技術は業界最高水準と考えられます... → After: 当社の技術は以下の特徴を持ちます...
     [概要3] Before: 処理速度は約2倍に向上... → After: 処理速度は1.8倍に向上（実測値）...
     ```
   - 修正不要の場合: `修正なし`
   - 注意:
     * テキストは最初の50文字まで表示（それ以上は「...」で省略）
     * 重要度が高い修正から最大3件まで表示
     * 改行はExcelのセル内改行（\n）で表現

9. **修正理由詳細**
   - 内容: 各修正項目について、なぜ修正が必要だったのかの理由と重要度
   - 形式: `[項目名]: [理由]([重要度]); [項目名]: [理由]([重要度]); ...`
   - 重要度分類:
     * 致命的: 事実と異なる、ハルシネーション
     * 高: 数値誤り、組織名誤り、重要情報の欠落
     * 中: 禁止表現、推測表現、文体の問題
     * 低: 軽微な表記ミス、形式的な問題
   - 例: `タイトル: 禁止表現「革新的」を削除(中); 概要1: 推測表現「考えられます」をハルシネーション判定(致命的); 概要3: 数値「約2倍」が原文「1.8倍」と不一致(高); 注目2: 体言止めを「である調」に修正(低)`
   - 修正不要の場合: `問題なし`

##### データの取得元とマージ方法

- **データソース**: `verification_results_YYYYMMDD_HHMMSS.xlsx`から検証情報を抽出
- **マージキー**: ID列を基準にデータを結合
- **配置位置**: 修正版Excelの既存列の最後尾に追加
- **欠損値処理**: 検証情報が存在しない行は空欄または「検証未実施」と記載
- **セル書式**:
  * 「主要修正Before/After」列はセル内改行を含むため、行の高さを自動調整
  * テキストの折り返しを有効化
  * フォント: MS Pゴシック、サイズ: 10pt

##### データ生成ロジック

検証プロセスで以下の情報を記録・生成する:

1. **修正トラッキング**:
   - 各項目（タイトル、概要1-4、注目1-3など）について、修正前後の値を記録
   - 修正タイプを自動分類（誤字、ハルシネ削除、数値訂正、表現改善、情報追加、情報削除）
   - 重要度を自動判定（致命的、高、中、低）

2. **修正内容の集約**:
   - 修正が行われた項目のリストを作成
   - Before/Afterのテキスト差分を抽出（最初の50文字）
   - 重要度順にソートして上位3件を選択

3. **修正理由の記録**:
   - 各修正について、検出された問題タイプを記録
   - 原文との照合結果を記録
   - 文章表現ガイドライン違反を記録

## Verification Criteria

### 事実性評価の基準

#### 原文存在性 (40点)
- **40点**: 記載内容が原文に明確に記載されている
- **30点**: 記載内容が原文から合理的に推測できる
- **20点**: 記載内容が原文に部分的に記載されている
- **10点**: 記載内容が原文にほとんど存在しない
- **0点**: 記載内容が原文に全く存在しない

#### 正確性 (30点)
- **30点**: 数値、固有名詞、事実関係が完全に正確
- **20点**: 軽微な誤りがある（表記のみの違いなど）
- **10点**: 重大な誤りがある（数値の間違いなど）
- **0点**: 事実と異なる情報が記載されている

#### 客観性 (20点)
- **20点**: 推測や拡大解釈が全くない
- **15点**: 軽微な推測や補足がある
- **10点**: 推測や拡大解釈が含まれている
- **5点**: 推測や拡大解釈が多く含まれている
- **0点**: ほぼ推測で構成されている

#### 表現適切性 (10点)
- **10点**: 文体、用語、表記が完全に適切
- **7点**: 軽微な表現の問題がある
- **5点**: 複数の表現の問題がある
- **3点**: 重大な表現の問題がある
- **0点**: 文章表現が不適切

### 総合評価の基準

#### A評価 (90-100点)
- 原文に完全に基づいており、推測や拡大解釈なし
- 文章表現が適切で、ガイドラインに完全準拠
- 軽微な修正のみで使用可能

#### B評価 (70-89点)
- ほぼ原文に基づいているが、一部改善の余地あり
- 文章表現はおおむね適切
- 部分的な修正で使用可能

#### C評価 (50-69点)
- 原文に基づいているが、推測や補足情報が混在
- 文章表現に複数の問題あり
- 相当の修正が必要

#### D評価 (0-49点)
- 推測や拡大解釈が多く含まれる
- 文章表現が不適切
- 大幅な修正または再作成が必要

## Output Format

### 検証レポートファイル

以下のファイルを生成:

1. **検証レポート (Markdown)**: `verification_report_YYYYMMDD_HHMMSS.md`
   - 人間が読みやすい詳細レポート
   - 問題箇所の具体的な指摘と改善提案

2. **検証結果 (Excel)**: `verification_results_YYYYMMDD_HHMMSS.xlsx`
   - 元のロングリストに検証結果列を追加
   - 各項目の事実性スコア
   - 問題の有無フラグ
   - 簡潔な問題指摘
   - **修正版Excelへの統合用データ**: 以下の9列を含む
     * 検証スコア (0-100点)
     * 評価ランク (A/B/C/D)
     * 検出問題数
     * 主な問題（セミコロン区切り）
     * 修正状況（修正済み/部分修正/未修正/修正不要）
     * 検証レポート参照（ファイル名）
     * 修正項目一覧（項目名×修正タイプ形式）
     * 主要修正Before/After（最大3件、セル内改行区切り）
     * 修正理由詳細（重要度付き）

3. **サマリーレポート (JSON)**: `verification_summary_YYYYMMDD_HHMMSS.json`
   - 機械可読な検証結果
   - スコア統計情報
   - 問題パターンの集計

## Usage Example

```python
# 検証の実行
import pandas as pd
from tech_longlist_verifier import verify_longlist

# ロングリストの読み込み
longlist = pd.read_excel('技術ロングリスト.xlsx')

# 検証実行
verification_results = verify_longlist(
    longlist=longlist,
    output_dir='./verification_results',
    verbose=True
)

# 結果の確認
print(f"平均スコア: {verification_results['average_score']}")
print(f"問題検出数: {verification_results['issues_count']}")
```

## Key Features

### 1. 包括的な事実性検証
- 全項目について原文との照合を実施
- 文単位での詳細な比較
- 数値、固有名詞の正確性確認

### 2. ハルシネーション検出
- 禁止表現の自動検出
- 推測・拡大解釈の識別
- 一般論混入の検出

### 3. 定量的評価
- 項目ごとの事実性スコア
- 総合評価（A/B/C/D）
- 問題の重大度分類

### 4. 実用的な改善提案
- 原文に基づく修正案の提示
- 文章表現の改善提案
- 追加すべき情報の提案

### 5. 複数形式の出力
- 人間向け詳細レポート (Markdown)
- データ分析向け結果 (Excel)
- 機械可読サマリー (JSON)

## Verification Process Details

### 原文照合の方法

#### 1. 完全一致の確認
- 記載内容が原文に文字列として存在するか確認
- 表現のゆれを考慮した照合

#### 2. 意味的一致の確認
- 記載内容が原文の意味と一致するか確認
- 言い換えや要約が適切か評価

#### 3. 推測の検出
- 原文に明記されていない情報の検出
- 「可能性」「考えられる」などの表現の検出

#### 4. 拡大解釈の検出
- 原文の表現を超えた記述の検出
- 原文にない因果関係の主張の検出

### エラーハンドリング

#### 情報ソースURL取得失敗時
- 取得失敗を記録
- スコアを「検証不可」とマーク
- 代替URLでの検証を試行

#### 原文が不明瞭な場合
- 複数の解釈が可能な場合は保留
- 他の情報ソースとの整合性を確認
- 検証コメントに不確実性を記載

## Quality Assurance

### 検証の品質保証

#### 二重確認の実施
重要な項目については:
- 複数の情報ソースとの照合
- 数値データの再確認
- 固有名詞の正確性確認

#### 検証者バイアスの排除
- 事実のみに基づく評価
- 主観的判断を避ける
- 明確な基準に基づく採点

#### 継続的改善
- 検証結果のフィードバック収集
- 検証基準の継続的見直し
- 検出パターンの学習と改善

## Notes

- このスキルは大量のWebFetch操作を伴うため、処理に時間がかかる場合がある
- 情報ソースURLにアクセスできない場合、その旨を記録して検証を継続
- 原文が複数の情報源に分散している場合、可能な限り全てを確認
- 専門的な技術内容については、原文の表現を尊重した評価を行う
- 検証結果はあくまで参考情報であり、最終的な判断は人間が行うべき

## Best Practices

### 検証前の準備
1. 全ての情報ソースURLが有効かを事前確認
2. 検証対象のロングリストが最新版であることを確認
3. 必要に応じてVPN等でアクセス制限を回避

### 検証中の注意点
1. 原文の文脈を考慮した評価
2. 専門用語の定義を確認
3. 数値データの単位と精度を確認
4. 組織名の表記ゆれに注意

### 検証後のフォロー
1. 検証レポートの内容を精査
2. 重大な問題から優先的に修正
3. 修正後に再検証を実施
4. 検証結果を次回の改善に活用
